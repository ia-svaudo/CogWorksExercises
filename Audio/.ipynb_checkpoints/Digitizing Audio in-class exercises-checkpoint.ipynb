{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f00119b0",
   "metadata": {},
   "source": [
    "## Digitizing Signals -- in-class exercises \n",
    "https://rsokl.github.io/CogWeb/Audio/digitizing_signals.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1776a8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from typing import Union, Callable, Tuple\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89cef1b",
   "metadata": {},
   "source": [
    "### Sampling Rate\n",
    "\n",
    "Given an analog signal that lasts for 127.2seconds, if we use sample at a rate of 0.5Hz, how many samples should we expect to collect? Compute your answer using pen and paper and using Python. Note that you can import the `floor` function from the standard library's `math` module, or you can simply call `int()` on the number to the same effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c5ecd8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import floor\n",
    "\n",
    "floor(127.2/0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e0c337",
   "metadata": {},
   "source": [
    "Complete the body of the following Python function that will extract samples that are evenly-spaced in time from an analog signal: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f615ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_sampler(signal, duration, sampling_rate):\n",
    "    \"\"\"\n",
    "    Extracts samples from an analog signal according to the specified sampling rate,\n",
    "    returning the times and the corresponding samples\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : Callable[[ndarray], ndarray]\n",
    "        Another Python function (i.e. a \"callable\"), which behaves like f(t)\n",
    "        and accepts a time value (in seconds) as an input and returns a\n",
    "        measurement (in volts) as an output. You can expect this to behave like\n",
    "        a vectorized function i.e. it can be passed a NumPy-array of input times\n",
    "        and it will return a corresponding array of measurements.\n",
    "\n",
    "    duration : float\n",
    "        The duration of the signal, specified in seconds (a non-negative float)\n",
    "\n",
    "    sampling_rate : float\n",
    "        The sampling rate specified in Hertz.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (times, samples) : Tuple[ndarray, ndarray]\n",
    "        The shape-(N,) array of times and the corresponding shape-(N,) array\n",
    "        samples extracted from the analog signal\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dbc601",
   "metadata": {},
   "source": [
    "__The standard PCM sampling rate used by the audio industry is 44,100 Hz.__ This number is based on the range of audio frequencies that humans can perceive – we can hear up to roughly __20,000 Hz__. To gain some insight into this, complete the following exercise. \n",
    "\n",
    "Aliasing is said to occur when the sampling process causes distinct signals to appear as being indistinguishable from one another. This exercise will demonstrate simple instance of temporal aliasing.\n",
    "\n",
    "Using the analog signal: \n",
    "\n",
    "<code>\n",
    "def f(t):\n",
    "    freq = 10 # Hz\n",
    "    return np.cos(2 * np.pi * freq * t)\n",
    "</code>\n",
    "\n",
    "Plot this __10 Hz__ sinusoidal signal densely (using many points, so that it appears to be continuous) over a __0.5 second__ interval. Now, use your `temporal_sampler` function from the previous exercise to sample this signal, __using a sampling rate that matches the frequency of the signal (10Hz)__; plot these samples on top of the analog signal. What do you notice about these samples? What is the simplest analog signal that you can imagine that would produce the exact same samples? Put another way: if all you saw were these samples, what is the analog signal that would you think they describe?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4f8be7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75004fbc",
   "metadata": {},
   "source": [
    "Now, re-sample the signal at with the sampling rate doubled and plot the results. Do these samples do a better job of representing our signal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaac58c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4eac8a2",
   "metadata": {},
   "source": [
    "This doubling between the highest frequency of an analog signal and the minimum viable sampling rate needed to discretize it \"faithfully\" has a special name: this sampling rate is known as the \"Nyquist rate\", as prescribed by the [Nyquist–Shannon sampling theorem](https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem). In general, one needs to use a sampling rate that exceeds the Nyquist rate (twice the highest-frequency component of the analog signal) in order to be able to faithfully reconstruct the analog signal from the samples.\n",
    "\n",
    "Reflecting on this, and given that we humans can perceive tones with frequencies up to roughly 20,000 Hz, why might the audio industry use a sampling rate of 44,100 Hz\n",
    "\n",
    "for digitizing audio signals?\n",
    "\n",
    "(Aside: If you have ever tweaked an “anti-aliasing” parameter in a video game’s settings, this is to help prevent aliasing in the spatially-sampled illumination values that will be displayed on your screen, which can cause undesirable pixelation effects.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d4c152",
   "metadata": {},
   "source": [
    "### Bit Depth\n",
    "https://rsokl.github.io/CogWeb/Audio/digitizing_signals.html#Bit-Depth\n",
    "\n",
    "We just reviewed the process of discretizing our analog signal in time by establishing a temporal sampling rate. Now we will discretize the magnitudes of the values that we record from out voltmeter; we will do this by establishing a bit-depth for our digitization process. This will, in effect, decide the number of “significant digits” that we use to record our measurements.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d335bd55",
   "metadata": {},
   "source": [
    "#### Quantization\n",
    "\n",
    "Write a python function called `quantize`, which performs the quantization process discussed above. Read the docstring for the function “stub” provided below. Note that you need not convert the quantized values to sequences of binary digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34241e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(samples, bit_depth):\n",
    "    \"\"\"\n",
    "    Given an array of N samples and a bit-depth of M, return the array of\n",
    "    quantized samples derived from the domain [samples.min(), samples.max()]\n",
    "    that has been quantized into 2**M evenly-spaced values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    samples : numpy.ndarray, shape-(N,)\n",
    "        An array of N samples\n",
    "\n",
    "    bit_depth: int\n",
    "        The bit-depth, M, used to quantize the samples among\n",
    "        2**M evenly spaced values spanning [samples.min(), samples.max()]\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    quantized_samples : numpy.ndarray, shape-(N,)\n",
    "        The corresponding array where each sample has been replaced\n",
    "        by the nearest quantized value\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import numpy as np\n",
    "    >>> samples = np.array([0, .25, .75, 1])\n",
    "    >>> quantize(samples, 1) # bit-depth 1: quantize among 2**1 values\n",
    "    array([0., 0., 1., 1.])\n",
    "    >>> quantize(samples, 2) # bit-depth 2: quantize among 2**2 values\n",
    "    array([0., 0.3333, .6666, 1.])\n",
    "    \"\"\"\n",
    "    # include this line of code to prevent yourself from\n",
    "    # trying such a large bit-depth that your computer\n",
    "    # becomes overburdened\n",
    "    assert bit_depth <= 14, \"Exceeding this bit-depth might tank your computer!\"\n",
    "\n",
    "    # STUDENT CODE\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947fae63",
   "metadata": {},
   "source": [
    "Find an mp3 file on your computer or device, and check to see how long the song is. Based on this number, and using the standard PCM encoding parameters:\n",
    "\n",
    " * f<sub>s</sub> = 44,100 Hz\n",
    " * N<sub>d</sub> = 16 bits\n",
    "\n",
    "compute how large you would expect this digital audio file to be, had it been written using PCM encoding, to the nearest tenth of a megabyte. Compare this to the actual size of the file on your computer. You should see that the size of mp3 file is considerably smaller than your calculated PCM file. This is because the mp3 format is a compressed audio format that can reduce the memory footprint of a recording by, among other things, filtering out data that would be imperceivable to the listener."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bd3654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1dbaf2b",
   "metadata": {},
   "source": [
    "Study the PCM sampling process depicted [here](https://rsokl.github.io/CogWeb/_images/fs_2_Nb_3.png). What is the temporal sampling rate and apparent bit-depth used here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1ec015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d057535",
   "metadata": {},
   "source": [
    "Study the code [here](https://rsokl.github.io/CogWeb/Audio/digitizing_signals.html#Code-For-Reproducing-Figures), for reproducing the figures from this chapter. Experiment with it and see how you can affect the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693124fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d21df1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
